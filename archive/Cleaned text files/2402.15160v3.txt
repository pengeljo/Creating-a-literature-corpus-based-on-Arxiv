Spatially-Aware Transformer for Embodied Agents


Introduction


Episodic memory is the type of memory that involves storing and retrieving events or episodes from an individual&apos;s life. This memory plays a crucial role in various human cognitive processes, such as enabling people to mentally travel back in time and remember past experiences like &quot;what you did yesterday&quot; [*REF*; *REF*]. It is also foundational in imagining the future and making effective decisions [*REF*]. Therefore, AI systems aiming to mimic human-like cognitive abilities would benefit from incorporating a form of episodic memory.


Currently, the primary approach for modeling episodic memory in AI is through transformers [*REF*; *REF*]. This approach represents an episodic memory as a sequence of experience frames. During the storing process, frames are stored in First-In-First-Out (FIFO) order with temporal-order embedding, called positional embsedding. While this FIFO inductive bias seems reasonable in modeling episodic memory due to the uni-directional flow of time in the physical world, various studies in cognitive science suggest that the formation and retrieval of episodic memories rely not only on the temporal aspects but also on another foundational axis of the physical world, the spatial axis, such as where we parked our car this morning [*REF*; *REF*; *REF*; *REF*].


Despite this significance, the spatial dimension has largely been overlooked in the modeling of transformer-based episodic memory. This can be attributed to two main reasons. First, since their invention, transformer models have mainly advanced in the language domain where spatial dimensions are not as prominent or meaningful. Second, in some domains, spatial annotations, such as the position of a robot, may not be as easily accessible as the temporal order indices. As a result, previous research have concentrated mainly on improving the accuracy of inferring such spatial information from experience, e.g., sequences of observations and actions [*REF*; *REF*; *REF*; *REF*].


However, beyond language, there are a broad range of domains, such as robotics and virtual agents in games, where the spatial dimension is just as natural and crucial as the temporal dimension. These agents need to navigate around rooms and various areas, and having spatially structured knowledge such as &quot;what happened where&quot; is essential for achieving the goal. Moreover, in many cases, the spatial information is as easily accessible as the time indices. In virtual worlds such as games, for instance, the ground-truth position information is easily provided from the game engine [*REF*] and for robots, it is already popular to provide such spatial information by a separate hardware system such as BLE beacons (if it is in-door) [*REF*], GPSs [*REF*], or algorithmically, e.g., SLAM [*REF*; *REF*]. Despite these circumstances, transformers currently only consider time axis.


In this work, we pose the question: what if spatial information is available as time indices to transformer-based models? Our goal is to investigate this overlooked aspect of transformers and to examine whether and how transformers can utilize the spatial axis. We approach this by deviating from the traditional focus on acquiring spatial information. Considering the widespread use of transformer architectures, as well as the growing accessibility of spatial information for embodied agents, we believe it is appropriate and timely to address this question.


FIGURE


To achieve this goal, we propose a series of transformer architectures called Spatially-Aware Transformers (SAT or SA-Transformer), which incorporate spatial information into transformers. This allows us to explore various feasible design choices and assess the pros and cons of these architectures. Specifically, we demonstrate that Spatially-Aware Transformers offer three main benefits. Firstly, they enhance spatial reasoning tasks. We show that without explicit spatial information (only with temporal information), it is challenging to solve various general spatial reasoning tasks, such as &quot;What has happened in the next room of the agent?&quot; (as shown in Figure (a)). However, providing spatial information makes these tasks much easier. Secondly, they enable efficient memory management. By incorporating spatial information, we can overcome the limitations of the FIFO memory, such as deleting important memory solely because it is old (as shown in Figure (b)). We can also implement structured approaches like place-centric hierarchical memory. We demonstrate that this structured memory improves effectiveness and efficiency in various place-centric tasks. To enhance memory utility further, we introduce the Adaptive Memory Allocator (AMA). Unlike traditional transformers that follows the FIFO policy for memory writing, AMA allows for adaptive selection of various writing strategies based on the goal. Finally, we demonstrate that these benefits extend across a wide range of machine learning problems, including supervised prediction, image generation, and reinforcement learning.


The main contributions of the paper are as follows: First, to our knowledge, we are the first to motivate, conceptualize, and introduce the notion of transformers capable of utilizing explicit spatial information. Second, we propose a series of SAT models designed to leverage spatial annotation. Third, we introduce the AMA method, which enables adaptable selection of various memory management strategies beyond the traditional FIFO-only strategy. Finally, we demonstrate that the advantages of SAT are not limited to a specific problem domain but extend across an array of machine learning applications, including supervised prediction, image generation, and reinforcement learning. We also release the source code for reproducibility.


Proposed Models


In this section, we describe the proposed Spatially-Aware Transformer (SAT) models. We begin with the simplest model, SAT-FIFO, and then discuss incorporating Place-Memory into SAT. Lastly, we introduce Adaptive Memory Allocation as a method for selecting a strategy other than FIFO based on the purpose of the downstream tasks.


Design 1: SAT with FIFO Memory


When location annotation *MATH* is available at each time step *MATH*, the most direct approach to make a spatially-aware episodic memory is simply to introduce the spatial embedding *MATH* and combine it with the time embedding *MATH* and the observation embedding *MATH*.
For the time and spatial embedding, the learnable embedding [*REF*] or sinusoidal positional embedding [*REF*] could be applicable, but in this literature, for simplicity, the sinusoidal positional embedding is used. This results in the experience frame *MATH*. Then, we add the experience frame to the episodic memory *MATH* in the conventional FIFO order. We call this simplest model SAT-FIFO and its memory structure is illustrated in Figure [1].


The main advantage of this approach is that it requires minimal alteration from the standard FIFO transformer in implementing the three basic operations of an episodic memory: *MATH* (*MATH*), *MATH* (*MATH*), and *MATH* (*MATH*). Here, *MATH* represents the query used to retrieve information from the episodic memory, and *MATH* is the output of the retrieval operation that will be used to solve downstream tasks. When it comes to removal, we generalize the operation by introducing a strategy *MATH* that determines how to remove experience frames. In the case of SAT-FIFO, the strategy *MATH* is fixed to FIFO. Although this approach endows the standard transformer with spatial awareness with minimal effort, it has limitations. For example, when the memory is full, the SAT-FIFO model has to remove the oldest experience first even if it is important to keep it for achieving the goal of the downstream task, e.g., as illustrated in Figure (b).


Design 2: SAT with Place Memory 


FIGURE


To resolve the limitations of SAT-FIFO, we introduce the Place Memory (PM) into the Spatially-Aware Transformers. In this model, called SAT-PM, the whole space is represented by a number of places and we maintain a place-wise episodic memory *MATH* one per place *MATH*, resulting in a place-centric hierarchical episodic memory *MATH*, as shown in Figure [2].


A place can be viewed as a cluster of locations and we observe that this place structure is naturally provided in many applications, e.g., via BLE beacons for indoor robots, via GPS and maps for autonomous driving cars, and via clustering algorithms in general. Even if the place structure must be learned through a clustering algorithm, we note that it is a relatively simple learning task due to the extremely low dimensionality (only 2 or 3) of the spatial coordinates. Moreover, as we shall show in Exp-5 in Sec. [3.2], it is not always necessary to have the ground truth place structure but an approximate one can be adequate in practice. Thus, in our experiments, we assume that the location is already clustered and thus replace the location embedding with place embedding *MATH*.


Place-Centric Store: To store the experience frame *MATH* obtained at place *MATH*, it is added to *MATH* in a FIFO order. The length of each place&apos;s episodic memory, *MATH*, can be set to *MATH* by default or manually adjusted with the prior&apos;s guidance. This allows the Place Memory to retain the memory of a room, regardless of how long ago it was visited, as long as the place&apos;s memory is not full. Unlike the flat FIFO transformer, this approach provides greater flexibility, balancing total memory capacity between time and space and help mitigate the issue shown in scenario (b) in Figure. However, if a place&apos;s memory is full, experience frames will still be removed in a FIFO order. Although such deletions are inevitable in any episodic memory with finite capacity, in the next subsection, we will discuss different memory management strategies that can handle this situation better than FIFO.


Place-Centric Hierarchical Read: A critical issue with transformers is their computation cost increasing with the number of memory items [*REF*]. One approach to mitigate this problem in an episodic transformer is to group a set of experience frames [*REF*] into chunks and perform hierarchical read operations. Specifically, we first select the top-k chunks by applying attention only across the chunk representations instead of individual experience frames. Then, we search for experience frames within those chosen chunks, as shown in Figure [8].


Previously, only time-based chunking was available. However, we observe that this approach can lead to problems in spatial environments. This is because experience frames of a place can be scattered across chunks located at various positions in the flat memory (depending on the visit order of a trajectory), and similarly, a chunk can contain mixed experiences from multiple places. This makes it more difficult to learn to search for these frames and develop a representation of what happened in a place. Utilizing spatial awareness, our Spatially-Aware Transformer provides a simple solution to address this issue. We first ensure that a chunk is filled only with experiences of the same place, and these chunks are managed within a place memory. In experiments, we show that this simple place-centric hierarchical reading is both fast and effective for spatial reasoning. For more details about the hierarchical operation, please refer to the Appendix [9.2].


Design 3: Adaptive Memory Allocator 


So far, we have assumed that experience frames are added to each place memory in the FIFO order. While using the inductive bias, &quot;recent knowledge is more important&quot;, is reasonable in modeling languages, it may not hold for various spatial problems. For example, a task may simply require retaining memory of a place that occurred at the beginning of an episode. Hence, to have a generic episodic memory, a more desired approach is to decide what to remember or forget adaptively according to the goal of the task.


However, a dilemma exists in practice. If we prioritize flexibility, the best approach would likely be to learn the optimal decision of which knowledge to be updated at each time step [*REF*; *REF*; *REF*]. However, it is known that this approach is notoriously difficult to train in practice, and we show it empirically in Appendix [11.6]. In fact, transformers completely remove the problem of learning to write into the memory by adopting the FIFO policy. This is one of the most crucial advantages of the transformer model, which allows it to be scalable in the language domain but at the cost of losing adaptability to find a better writing strategy.


To address this issue, we propose a simple and practical method called Adaptive Memory Allocator (AMA) that balances flexibility of the writing policy and ease of training. AMA extends the space of memory management strategies to multiple strategies by allowing the developer to design the space of various memory management strategies, denoted as *MATH*, based on their prior knowledge. For instance, *MATH* can be FIFO, *MATH* can be Last-In-First-Out (LIFO), *MATH* can be Least-Visited-First-Out (LVFO), and so on. This way, the traditional transformer can be viewed as a special case where there is only one strategy, i.e., FIFO. Also, these strategies are similar to CPU-cache management algorithms [*REF*], but our goal is to learn how to choose between them. It is important to note that the primary value of this method lies not in what the strategies themselves are, as they can be created in various ways based on prior knowledge. Rather, the value lies in the fact that Spatially-Aware transformers enable the selection of these strategies (other than FIFO) in a way that optimizes downstream tasks.


The problem is then formulated as choosing the best strategy based on the agent&apos;s current intention or task description *MATH*. For example, the agent can be given *MATH* &quot;What object did you see in your left room?&quot; This problem can be addressed by learning a policy *MATH*. We implement this as a one-step Q-learning policy *MATH*, where *MATH* is the parameter of the value function. One might think that, if the number of strategies is small enough, we can simply try all strategies and pick the best one. Then, we do not need to learn how to choose one. However, as there are almost infinitely many ways of describing a task, e.g., via language, it should be able to generalize to the variations of task descriptions. By learning the context-aware policy in AMA, we can learn to choose a suitable strategy even if an unseen (as a variation of) task description is given at test time. AMA is illustrated in Figure [3], and the pseudo-code for learning algorithm with SAT and AMA is presented in the Appendix [9.3].


Experiments


This section presents an empirical evaluation of the Spatially-Aware Transformer (SAT) and Adaptive Memory Allocator (AMA) across various environments and downstream tasks. We begin by evaluating the models on prediction tasks in the Room Ballet environment. Then, we demonstrate its capability to build an action-conditioned world model and spatially-aware image generation model. Lastly, we showcase the use of SAT-AMA for training a downstream reinforcement learning policy. Each baselines and tasks are explained in each of the experiment section. In the experiments, observation, the time-step, and space are sequentially presented to the agent. Afterward, a query is provided. For some experiments, the task type is introduced at the episode&apos;s commencement to select the proper memory allocation strategy. The agent is expected to integrate these inputs to solve the tasks. The more details are in Appendix [10.1].


Supervised Prediction with Room Ballet


FIGURE


In this section, we use the Room Ballet environment, inspired by the Ballet task described in [*REF*]. Figure illustrates the environment, which consists of multiple rooms. By default, there are 9 rooms, but this can be expanded to 16 and 25 in Exp-2. Each room represents a &quot;place&quot; and contains a dancer. In each episode, the agent is placed randomly in one of the rooms and moves through the rooms via random walk. Upon entering a room, the agent observes a complete dance performance consisting of 32 frames, performed by the dancer in that room. In each episode, a dancer type (i.e., the appearance of a dancer) and a dance type (i.e., the performance) are randomly and independently assigned to each room.


Exp-1. Implicit derivation of spatial information in transformers


To verify that the transformers can derive the spatial information, we designed a spatial reasoning task on the Room Ballet environment, which we call the Next Ballet task. In this task, the agent visits 40 rooms (1280 steps) through a random walk with the four actions. Afterward, when provided with a query image showing a dancer&apos;s appearance, it is tasked to predict the type of dance that was performed in the next room of the queried dancer in clockwise order.


Although transformers have demonstrated impressive performance across various applications [*REF*; *REF*; *REF*; *REF*; *REF*], it is unclear whether they can infer spatial information from navigation trajectories consisting of observations, actions, and time. To investigate this, we evaluate the following models: a standard transformer only with temporal order information T-FIFO, a transformer with temporal order and action T-FIFO+A, and a transformer with spatial information SAT-FIFO. Also, to ensure that memory capacity does not affect the results, we set the memory size to be large enough to store all observations.


As shown in the Figure [5] (a), we can see that the transformer using only temporal order without actions (T-FIFO) completely fails on this spatial reasoning task, suggesting its inability to develop an internal representation of the space from the ordered sequence of observations, as expected in the Thought Experiment. When we additionally provide the action information (T-FIFO+A), it began to show a better performance but still significantly inadequate to accurately solve the spatial reasoning problem by inferring the dancer&apos;s room location. These results suggest that inferring spatial information from observations and actions is not trivial in practice, though it may not be totally impossible. On the contrary, explicitly incorporating spatial information, SAT successfully solves the task, demonstrating the importance of having explicit spatial information in spatial reasoning tasks.


FIGURE


Exp-2. Place-centric hierarchical reading vs Time-centric hierarchical reading


To demonstrate that place-centric chunking proposed in Section [2.2], is more beneficial for spatial task compared to traditional time-based chunking, we introduce a new and more realistic task called &quot;Short Stay&quot; in the Ballet environment. In this task, unlike the previous one, the agent is not required to stay in a room until it observes the entire dance.
Instead, the agent exhibits more natural behavior by being able to move to a neighboring room at any time step. After making 1280 such moves, the agent is presented with a query dancer image and tasked with predicting its dance type. To verify the efficacy of the place-centric hierarchical SAT, we compared three models: (i) SAT-FIFO, (ii) SAT-FIFO with time-centric hierarchical read (SAT-FIFO-TH), and (iii) SAT-PM with place-centric hierarchical read (SAT-PM-PH). The accuracies are measured after 200K training steps, and the chunk size is set to *MATH*. More details about this task are provided in Appendix [10.3].


As shown in Figure [5] (b), it is evident that SAT-PM-PH consistently outperforms SAT-FIFO-TH and SAT-FIFO in all scenarios. Furthermore, as the number of rooms increases, the performance gap between SAT-FIFO-TH and SAT-PM-PH also widens. We observe that this is because SAT-FIFO-TH allows for temporally consecutive experiences from different places to be grouped together within a chunk. Similarly, experiences from the same place can be spread across multiple chunks. Consequently, gathering information about an event that occurred in a specific location by collecting scattered experience frames across multiple chunks remains a more challenging task for SAT-FIFO-TH, despite its use of place encoding and computational speed enhancement due to the hierarchy. On the other hand, SAT-PM-PH easily overcomes this challenge since a chunk contains only experiences from the same place. When compared to the non-hierarchical SAT-FIFO, SAT-PM-PH not only achieves better accuracy but also demonstrates faster inference speed, as in Table [1] in Appendix. This is because SAT-PM-PH only attends to the memory in the top- *MATH* relevant chunks, while SAT-FIFO needs to attend to the entire memory.


Exp-3. Learning to select memory allocation strategy with AMA


FIGURE


In this section, we assume that the memory capacity is limited and demonstrate that with SAT-AMA, it is possible to learn to find a proper memory management strategy that best fits the downstream task and that it is better than always using FIFO. We first introduce four strategies: First-In-First-Out (FIFO), Last-In-First-Out (LIFO), Most-Visited-First-Out (MVFO), and Least-Visited-First-Out (LVFO).
FIFO/LIFO replace the oldest/newest observation in the memory. MVFO/LVFO replace the oldest memory from the most/least frequently visited room.
Note that whether these strategies are good or not is not the primary value of this work. Rather, they are examples of prior strategies that can be designed.


Then, we introduce four different tasks, one for each strategy: Ballet-FIFO, Ballet-LIFO, Ballet-MVFO, and Ballet-LVFO. In the tasks, which consist of a total of 9 rooms as shown in Figure, the agent changes rooms 17 times (for a total of 576 steps) using random walk. This allows the agent to visit a room multiple times, potentially encountering multiple distinct dancers in a room. It is important to note that we limit the memory capacity to 288 and thus a half of the total episode steps must be chosen to be removed according to the management strategy. We note that the agent changes rooms after observing a complete dance performance in those tasks.


In each task, the agent is asked to predict the dance type of a queried dancer image. The selection of the query dancer follows a specific strategy, ensuring that it can only be answered correctly if the correct storage strategy was used. For instance, in the Ballet-LIFO task, the query dancer is always selected from the oldest half of the episode.
Therefore, if the FIFO strategy was used, the memory does not contain the oldest half, making it impossible to correctly answer the query.
However, if LIFO is chosen, the memory always retains the necessary experience to answer the query. Similarly, in the Ballet-MVFO/LVFO tasks, the agent is asked to predict the most recently observed dances within each room and the dances in the most frequently visited room, respectively. Importantly, given a task, the agent does not know what the best strategy is but needs to learn to choose it via AMA. Note that we use place-centric hierarchical read for selecting MVFO/LVFO, and time-centric hierarchical read for selecting in FIFO/LIFO in AMA. More details about the tasks are provided in Appendix [10.4].


Figure depicts the performance of different task-strategy pairs. As anticipated, we observe strong performance in the diagonal terms of the matrix when the strategy aligns with the task.
Conversely, when the strategy does not match (i.e., the off-diagonal terms), the performance deteriorates. Notably, in the 5th column, we present the performance of SAT-AMA. SAT-AMA achieves comparable performance to strategies specifically designed for each task (the diagonal terms) as it learns to discover suitable strategies for each task.


Exp-4. Generalization of SAT-AMA to multi-task descriptions


In Exp-3, we demonstrated that SAT-AMA can learn to select an appropriate strategy for a single task. However, in this specific scenario, it is possible to find the correct strategy by trying out all configurations, as there are only four tasks and four strategies. In a more realistic scenario, it is common to ask the agent to solve multiple tasks with diverse formats, such as language descriptions (as described in Sec. [2.3]). In such cases, the model should be able to generalize to the diverse variations of task descriptions. In this setting, it is impossible to try all possible configurations.


To test this, we mapped each task in Exp-3 to a set of natural language descriptions. We created 20 different descriptions for each task. For example, for the Ballet-LVFO task, we provided descriptions such as &quot;Recall the dancers in the room the agent frequented the most&quot; or &quot;Reflect on the dancers in the room that seemed to be the agent&apos;s favorite&quot;. During training, we randomly selected 64 mixed descriptions (16 per task) and used the remaining 16 descriptions (4 per task) to evaluate SAT with AMA. We name this version of SAT as SAT-AMA-Lang. All descriptions used in the experiment can be found in Appendix [10.5]. For AMA, the description is given as an embedding from the OpenAI embeddings API. The results are shown in Figure [5] (c). It is important to note that the accuracy in the evaluation is an average of three different training/evaluation description sets. In this case, SAT-AMA achieved an accuracy of over 95%. This indicates that AMA can be extended to generalize to the diverse variations of task descriptions and has potential in broad applications such as language-instructed robots.


FIGURE


Episodic Imagination via Image Generation 


In this section, we demonstrate the potential of applying SAT to more complex tasks and environments: action-conditioned episodic image generation requiring multi-step spatial reasoning, and episodic image generation with AMA.


Exp-5. Action-conditioned generation in the FFHQ world


We demonstrate the capability of the SAT to generate conditioning on actions while navigating an environment to see its potential to implement an episodic world model [*REF*; *REF*; *REF*; *REF*]. To test this, we designed a navigation task on the facial images from FFHQ dataset [*REF*], where 62,000 face images are used for training and 7,000 images among the remaining images are used for evaluation. The environment is a face image which is considered as a *MATH* grid map. The agent observes a partial image of the face, as shown in Figure [7] (a), while navigating the image provided with an action (up, down, left, right) at each step. During the observation phase, the agent spawns in a random location and performs a random walk for 256 steps. During the generation phase, at a random position, it is given a sequence of random actions of length 32. Then, the task is to generate images corresponding to the queried action sequence by utilizing the episodic memory constructed during the observation phase. Therefore, this task requires multi-step spatial reasoning. See Figure [16] in Appendix for more visualization. For this task, 2-D sinusoidal positional embedding that encodes x and y axes separately, is utilized for the space embedding. The comparative analysis of the embedding types for the space embedding is discussed in Appendix [11.9].


To verify the efficacy of the SAT-FIFO, we compared it with T-FIFO and T-FIFO+A. The results are shown in Figure [6] (a) and [7] (b). Since this task is a harder version of the Next Ballet task in Exp-1 due to a larger map, T-FIFO and T-FIFO+A failed to solve it. SAT-FIFO, on the other hand, outperformed them and generated high-quality images. We note that this result is from the evaluation set which contains facial images that are unseen during training. This result suggests that SAT can handle complex spatial reasoning on unseen visual environments. Additionally, we investigated the effect of using approximate place structures by changing the number of clusters (*MATH*). As shown in [6] (a), SAT-PM(*MATH*) showed robust performance across different place clustering. See Appendix [11.7] for more results and discussion.


FIGURE


Exp-6. Image generation in 3D first-person view environment


Next, we evaluate SAT with AMA for the image generation in the MiniWorld environment [*REF*], a 3D environment where an agent navigates in the first-person view setting. As shown in Figure [10] in the Appendix, the agent is placed at the center of a room with four dancers positioned at each side of the room (North, South, East, and West), each performing a distinct dance. The agent observes the room by rotating at a random degree between 3 and 7 in a clockwise order. Afterwards, the agent is tasked with generating a dance video featuring the queried dancer. Due to the rotation, during the observation phase, the agent observes the dance from various viewpoints, as shown in Figure [10]. However, during the generation phase, the agent is asked to generate the dance from the front view. Therefore, the model cannot simply copy the dance from its episodic memory, but instead needs to develop a proper representation of the dance from the episodic memory and decode it accordingly. Similar to the Ballet tasks, we tested four different types of queries: FIFO, LIFO, MVFO, and LVFO. As depicted in Figures [6] (b) and [10], we can see that SAT-AMA successfully learns to choose the appropriate strategy for the given task. In contrast, SAT-FIFO performs worse because it loses necessary memory if it is older than the memory capacity. More details about the experiment are provided in Appendix [10.6].


Reinforcement Learning Agent 


Lastly, we test an RL agent equipped with SAT-AMA memory. The task involves two rooms. The agent is initially placed in a room with a single box of a random color (either blue or green). After staying four steps in the room, the agent is transported to the second room which is larger and contains multiple yellow boxes, and navigates for 80 steps.


FIGURE


After this observation phase, the agent is warped back to the first room, where it is tasked to collect the box that matches the color of the box observed initially. The memory capacity is limited to 40, a half of the number of total steps in the second room. We use Proximal Policy Optimization (PPO) [*REF*] for agent learning. AMA is designed to learn through the reward from the environment and to choose a strategy between FIFO and MVFO. As shown in Figure [6] (c), SAT-AMA successfully learned to select the appropriate strategy (MVFO) and solve the task. While it only needs to choose one out of two strategies, it is important to note that this still a challenging task where AMA needs to learn through sparse rewards and many interaction steps, and in the first-person view 3D environment.


Related Works


Transformers have been widely used in various applications [*REF*; *REF*; *REF*; *REF*], however, their high computational cost has been a major drawback, especially for reinforcement learning [*REF*]. To address this issue, several methods have been proposed to reduce the computational cost of transformers without sacrificing their long-term memorization ability [*REF*; *REF*]. In this paper, we propose a new type of hierarchical read operation that is more efficient for place-centric tasks. We also propose a memory management method based on reinforcement learning that aims to optimize memory usage.


In parallel, there has been growing interest in using spatial information for embodied agents [*REF*; *REF*; *REF*; *REF*; *REF*]. Some studies have focused on using spatial information to improve navigation performance [*REF*; *REF*], while others have aimed to construct cognitive maps [*REF*; *REF*; *REF*]. In this study, we investigate incorporating spatial information into episodic memory. We show that this can improve performance and memory usage efficiency on spatial reasoning tasks without sacrificing performance.


Conclusion and Limitations 


Transformer-based episodic memory has utilized temporal order to serialize experience frames. In this paper, we explore the potential of incorporating the spatial axis as another fundamental aspect of the physical world. We argue that this is crucial for embodied agents and introduce the concept of Spatially-Aware Transformers (SAT). We propose different SAT architectures, starting from the simplest SAT-FIFO to SAT with place memory, which includes a hierarchical episodic memory centered around places. Furthermore, we introduce the Adaptive Memory Allocation (AMA) method, which provides a more flexible memory management strategy beyond the FIFO memory writing approach. Through experiments, we assess the improved performance of these methods and demonstrate their applicability to a wide range of machine learning problems.


Limitations. Despite the aforementioned contributions, this work is based on several simplifying assumptions as the first to propose the concept of spatially-aware transformers. One of the main assumptions is its reliance on spatial annotation. Although spatial annotation is widely available in many embodied agent applications, incorporating the learning of spatial representation alongside its usage could enhance the applicability of the proposed models. Another limitation is the generality of the AMA method. While it offers more flexibility than FIFO, it still relies on a set of predefined strategies. While it would be ideal to discover the strategy from scratch, previous works like the Neural Turing Machine [*REF*; *REF*] have demonstrated that this approach can introduce significant training complexity, limiting its practical application. Thus, there is a need for a new method that improves both flexibility and ease of training. Lastly, while in this work we focused on spatial reasoning tasks, there would also be non-spatial reasoning tasks in spatial environments. Generalizing the proposed method to handle such cases would also be an interesting future direction.